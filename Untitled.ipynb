{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87aa338",
   "metadata": {},
   "source": [
    "# Introduction to deap\n",
    "\n",
    "The code implementation of GA algorithm is this notebook is completely constructed as summary of the reference book:\n",
    " **algortimos genéticos en python** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924231c",
   "metadata": {},
   "source": [
    "# Learning by doing...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c644ca9",
   "metadata": {},
   "source": [
    "## Benchmark functions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a815b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creamos los objetos para definir el problema y el tipo de individuo\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Gene generation\n",
    "toolbox.register(\"attr_uniform\", random.uniform, -100, 100)\n",
    "\n",
    "# Individuals and population\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_uniform,2)\n",
    "toolbox.register(\"population\", tools.initRepeat , list , toolbox.individual, 30)\n",
    "\n",
    "individuo = toolbox.individual()\n",
    "poblacion = toolbox.population()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a58765",
   "metadata": {},
   "source": [
    "## creator.create()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24eeb4",
   "metadata": {},
   "source": [
    "# Important paramters\n",
    "CXPB-> probability of crossovver\n",
    "MUTPB-> probability of mutation\n",
    "NGEN-> number of generations\n",
    "\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    random.seed(1)\n",
    "    CXPB, MUTPB, NGEN = 0.5, 0.2, 20\n",
    "    pop  = toolbox.population()  # create the initial population\n",
    "    hof  = tools.HallOfFame(1) # keep the better individual in each gestneration\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values) #to keep statistics about population in each population\n",
    "    # register statiticals functions of numpy library\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    logbook = tools.Logbook()\n",
    "    pop, logbook  = algorithms.eaSimple(pop, toolbox, cxpb = CXPB, mutpb = MUTPB, \n",
    "                                        ngen = NGEN, stats = stats,\n",
    "                                        hallofffame = hof , verbose = True)\n",
    "    return hof, logbook\n",
    "```\n",
    "*deap* have several implementations GA,  _eaSimple_ is our first and basic algorithm; the parameters are:\n",
    "*population, toolbox,  cxpb, mutpb, ngen, stats halloffame, verboose* and will return us final population and logbook( evolution registry).\n",
    "\n",
    "Execution of the algorithm.\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    best, log = main()\n",
    "    print(\"The better fitness\" \\%best[0].fitness.values)\n",
    "    print(\"solution\" \\%best[0])\n",
    "```\n",
    "what we can see? (gen) the number of generatios, number of evaluations ( number of  individuals that has been evaluated or has been modified by the operators, remember that are probabilistics operators.)(nevals), mean performance of the population (avg), standard deviation (std) .....\n",
    "\n",
    "GA is stochastic therefore  we need execute it several times:\n",
    "\n",
    "changes:\n",
    "* Increase the population until there is not significant improvements.\n",
    "* Increase the number of generations until the algorithm show convergence.\n",
    "* Change the probability of crossover and mutation.\n",
    "\n",
    "\n",
    "tools.Logbook() store the information as a dictionaries.\n",
    "\n",
    "\n",
    "## plotting the covergence of GA\n",
    "```python\n",
    "def plot(log):\n",
    "    gen = log.select(\"gen\")\n",
    "    fit_mins = log.selec(\"min\")\n",
    "    fit_maxs = log.select(\"max\")\n",
    "    fit_avg = log.select(\"avg\")\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(gen, fit_mins, \"b\")\n",
    "    ax1.plot(gen, fit_maxs, \"r\")\n",
    "    ax1.plot(gen, fit_avg, \"--k\")\n",
    "    ax1.fill_between(gen, fit_mins, fit_maxs,\n",
    "                     where=fit_maxs >= fit_mins, facecolor ='g', alpha = 0.2)\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabl(\"Fitness\")\n",
    "    ax1.set_ylim([-10 ,160])\n",
    "    ax1.legend([\"Min\", \"Max\", \"Avg\"], loc=\"lower center\")\n",
    "    plt.grid(True)\n",
    "```\n",
    "    \n",
    "### How implemented it ?\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(1)\n",
    "    betters = list()\n",
    "    for _ in range(20):\n",
    "        best = main()\n",
    "        betters.append(best[0].fitness.values)\n",
    "mean = np.mean(betters)\n",
    "best = max(betters)\n",
    "print(mean, best)\n",
    "plot_evolution(log)\n",
    "```  \n",
    "\n",
    "What should be show the graph ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ecdb6",
   "metadata": {},
   "source": [
    "# Solve Quadratic function\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = ax^{2} + b^{x} + c\n",
    "\\end{equation}\n",
    "\n",
    "In a analytical way it  is enough $f'(x^{*}) = 0$.\n",
    "\n",
    "Therefore, $f'(x) = 2ax + b = 0$ getting x, we have $x^{*} = \\frac{-b}{2a}$ the exactly solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d558d79",
   "metadata": {},
   "source": [
    "## Why gradient descent work?\n",
    "\n",
    "\n",
    "## Partial derivate \n",
    "Is a special case of directional derivattive.\n",
    "\n",
    "\n",
    "This need additional information(derivatives) and its performance is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6988d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b,c = -1, 30, 123\n",
    "\n",
    "domL,domU = 0,30\n",
    "\n",
    "def optimal(a,b):\n",
    "  return -b/(2*a)\n",
    "\n",
    "def fitness(x,a,b,c):\n",
    "  return a*(x**2) + b*x + c\n",
    "y = [fitness(x,a,b,c) for x in np.linspace(domL, domU , 200)]\n",
    "plt.plot(np.linspace(domL, domU, 200), y)\n",
    "\n",
    "plt.axvline(x = optimal(a,b), color = 'red', linestyle='--', ymax =0.96)\n",
    "print(fitness(optimal(a,b),a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbfe58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.996365392199024, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def quadratic(a,b,c,x ):\n",
    "  return a*x**2 + b*x + c\n",
    "\n",
    "# Derivative of the function\n",
    "def Dxquadratic(a,b,x):\n",
    "  return 2*a*x + b\n",
    "\n",
    "def GDS_Quadratic( x0, problem =1, learning_rate=0.0001, iterations_max=99900, error_max = 0.001, a=a,b=b):\n",
    "  gradient = Dxquadratic   # We defined previously\n",
    "  xi = x0\n",
    "  iters = 0\n",
    "  error = 100\n",
    "  while (iters < iterations_max) and (error > error_max):\n",
    "    if problem ==1: \n",
    "        xj = xi - learning_rate *(-1)*gradient(a,b, xi)  # Maximization\n",
    "    else:\n",
    "        xj = xi - learning_rate * gradient(a,b, xi)  #Minimization\n",
    "    error = abs(xi-xj)\n",
    "    xi = xj\n",
    "    iters += 1\n",
    "  return xj,iters\n",
    "GDS_Quadratic(1, learning_rate=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673c826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tstd    \tmin     \tmax\n",
      "0  \t100   \t-2349.23\t2614.26\t-8347.56\t348\n",
      "1  \t61    \t-290.718\t903.346\t-4578.64\t348\n",
      "2  \t66    \t253.529 \t221.244\t-1433.68\t348\n",
      "3  \t68    \t339.247 \t16.2991\t260.951 \t348\n",
      "4  \t67    \t344.912 \t8.97039\t286.057 \t348\n",
      "5  \t59    \t346.561 \t12.5591\t221.728 \t348\n",
      "6  \t61    \t347.552 \t1.83121\t333.532 \t348\n",
      "7  \t53    \t347.233 \t6.82709\t279.514 \t348\n",
      "8  \t54    \t347.44  \t3.90189\t318.784 \t348\n",
      "9  \t58    \t347.826 \t1.7303 \t330.61  \t348\n",
      "10 \t58    \t347.571 \t4.14473\t306.349 \t348\n",
      "11 \t54    \t347.905 \t0.943829\t338.514 \t348\n",
      "12 \t60    \t347.606 \t3.34424 \t314.703 \t348\n",
      "13 \t63    \t347.996 \t0.0385529\t347.613 \t348\n",
      "14 \t62    \t347.948 \t0.2827   \t345.975 \t348\n",
      "15 \t54    \t347.324 \t5.0523   \t301.492 \t348\n",
      "16 \t69    \t347.989 \t0.0979571\t347.018 \t348\n",
      "17 \t66    \t346.271 \t13.777   \t214.968 \t348\n",
      "18 \t66    \t347.871 \t0.921404 \t339.165 \t348\n",
      "19 \t67    \t347.332 \t6.25396  \t285.221 \t348\n",
      "20 \t50    \t347.405 \t5.84581  \t289.244 \t348\n",
      "The better fitness (348.0,)\n",
      "solution 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/ivan/.local/lib/python3.10/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# deap optimization\n",
    "import random \n",
    "import math \n",
    "import numpy as np\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# individuals and problem\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# The objective function or fitness function will be quadratic()\n",
    "toolbox = base.Toolbox()\n",
    "#Genes \n",
    "toolbox.register(\"rand09\", np.random.randint, 0, 100)  # this line \n",
    "# individual definition\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.rand09, 3)\n",
    "# Population\n",
    "toolbox.register(\"Population\", tools.initRepeat, list , toolbox.individual, 100)\n",
    "\n",
    "\n",
    "def listTox(array):\n",
    "    total = 0\n",
    "    for i in range(len(array)):\n",
    "        total = total + (array[i] / (10**i))\n",
    "    return total\n",
    "\n",
    "def quadratic(x):\n",
    "    x = listTox(x)\n",
    "    a,b,c = -1,30,123  # Parameters to assess \n",
    "    res = a*(x**2) + b*x+ c\n",
    "    return res, \n",
    "\n",
    "\n",
    "# Genetic operations\n",
    "toolbox.register(\"evaluate\", quadratic)  # The quadratic function\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=5 , indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize = 3)\n",
    "\n",
    "\n",
    "def plot(log):\n",
    "    gen = log.select(\"gen\")\n",
    "    fit_mins = log.selec(\"min\")\n",
    "    fit_maxs = log.select(\"max\")\n",
    "    fit_avg = log.select(\"avg\")\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(gen, fit_mins, \"b\")\n",
    "    ax1.plot(gen, fit_maxs, \"r\")\n",
    "    ax1.plot(gen, fit_avg, \"--k\")\n",
    "    ax1.fill_between(gen, fit_mins, fit_maxs,\n",
    "                     where=fit_maxs >= fit_mins, facecolor ='g', alpha = 0.2)\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabl(\"Fitness\")\n",
    "    ax1.set_ylim([-10 ,160])\n",
    "    ax1.legend([\"Min\", \"Max\", \"Avg\"], loc=\"lower center\")\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(1)\n",
    "    CXPB, MUTPB, NGEN = 0.5, 0.2, 20\n",
    "    pop  = toolbox.Population()  # create the initial population\n",
    "    hof  = tools.HallOfFame(1) # keep the better individual in each gestneration\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values) #to keep statistics about population in each population\n",
    "    # register statiticals functions of numpy library\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    logbook = tools.Logbook()\n",
    "    pop, logbook  = algorithms.eaSimple(pop, toolbox, cxpb = CXPB, mutpb = MUTPB, \n",
    "                                        ngen = NGEN, stats = stats,\n",
    "                                        halloffame = hof , verbose = True)\n",
    "    return hof, logbook\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best, log = main()\n",
    "    print(\"The better fitness\" ,best[0].fitness.values)\n",
    "    print(\"solution\" , listTox(best[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b995c",
   "metadata": {},
   "source": [
    "# Gradient descent or Genetic?\n",
    "\n",
    "The gradient descent could be stucked in a local point, while genetic have some mechanism to reach  out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e258cee",
   "metadata": {},
   "source": [
    "## TSP modelling\n",
    "\n",
    "\n",
    "Hereforth, $n$ the number of cities, $d_{ij}$ the distance among the city $j$ and $i$. $x_{ij}$ is a binary var,will be $1$ if the path from $i$ to $j$ has been consider, and $0$ in otherwise.\n",
    "\n",
    "\\begin{equation}\n",
    "\\min \\sum_{i=1}^{n} \\sum_{j=1}^{n} d_{ij} x_{ij} \\\\\n",
    "S.t: \\\\\n",
    "\\sum_{j=1}^{n} x_{ij} = 1, \\forall i  \\\\\n",
    "\\sum_{i=1}^{n} x_{ij} = 1, \\forall j\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Ciclo hamiltoniano \n",
    "\n",
    "TSP requiere find the namiltonian cycle of minimun disticance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa34bc",
   "metadata": {},
   "source": [
    "# Complexity of TSP\n",
    "\n",
    "\n",
    "\n",
    "## Applications of TSP\n",
    "transport, logistic and routing of autonomos vehicles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27556702",
   "metadata": {},
   "source": [
    "# The posible solution \n",
    "```python\n",
    "[A,B,C,D] \n",
    "```\n",
    "therefore the distance will be; $d(A,B) + d(B,C) + d(C,D) + d(D,A)$\n",
    "\n",
    "\n",
    "The data was extracted of here; https://simplemaps.com/data/co-cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0abc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"cities.csv\")\n",
    "data = data[data['capital']=='admin'].sample(n=10, random_state=4).reset_index(drop=True)\n",
    "capitals = data['city'].unique()\n",
    "cities_dict = {}\n",
    "for index in data.index:\n",
    "    cities_dict[data.loc[index,'city']] = [data.loc[index, 'lat'] , data.loc[index, 'lng']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0aa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic TSP implementation:\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import algorithms\n",
    "from deap import creator\n",
    "from deap import base\n",
    "from deap import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d858ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg    \tstd    \tmin    \tmax    \n",
      "0  \t100   \t61.8257\t6.87643\t44.3461\t73.7989\n",
      "1  \t100   \t51.1625\t4.04307\t43.4313\t61.2367\n",
      "2  \t100   \t45.5594\t2.37202\t36.6613\t51.2928\n",
      "3  \t100   \t41.4613\t2.59711\t36.6613\t46.3621\n",
      "4  \t100   \t37.6923\t1.52116\t36.3319\t42.4333\n",
      "5  \t100   \t36.5296\t0.161396\t36.3319\t36.6613\n",
      "6  \t100   \t36.3286\t0.133531\t35.5103\t36.6613\n",
      "7  \t100   \t36.1676\t0.328629\t35.5103\t36.3319\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "The fitness (36.33188823828526,) and he better path is : \n",
      "\n",
      "['Puerto Carreño' 'Ríohacha' 'Barranquilla' 'Montería' 'Quibdó' 'Popayán'\n",
      " 'Florencia' 'Armenia' 'Yopal' 'Mitú']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# Fitness function and another neccesary funtcions\n",
    "def distanceF(cityA, cityB):\n",
    "    return ((cityA[0] - cityB[0])**2  + (cityA[1] - cityB[1])**2)**(1/2)\n",
    "\n",
    "# Evaluate a path\n",
    "def eval_tsp(individual):\n",
    "    index_test = individual\n",
    "    path_test = capitals[index_test]\n",
    "    route = distanceF(cities_dict[path_test[0]],  cities_dict[path_test[-1]]) # The first and the last city to complete\n",
    "    for i in range(len(path_test)-1): \n",
    "        route += distanceF(cities_dict[path_test[i]], cities_dict[path_test[i+1]])\n",
    "    return route, # It is important return a tuple\n",
    "\n",
    "\n",
    "IND_SIZE = len(capitals)  # the number of cities to find the closest path\n",
    "\n",
    "# Creating problem and kind of individual:\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights = (-1.0,))\n",
    "creator.create(\"Individual\", list , fitness=creator.FitnessMin)\n",
    "## Toolbox \n",
    "## create the tours or paths..\n",
    "#the strategy is store the list in a list and create indices as individuals or tours.\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"indices\", random.sample, range(IND_SIZE), IND_SIZE)   # draw k samples without replacement including\n",
    "                                                                        # zero  and excluding N\n",
    "#Given that \"indices\" returns us a complete individual dont need uses init.Repeat otherwise, init.Iterate\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n",
    "# two paratermers accep initIterate ( container(Individual) and Func(indices a iterable function))\n",
    "# Create the initial population\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual,100)\n",
    "\n",
    "#Genetic Operators (preserve the names)\n",
    "toolbox.register(\"mate\", tools.cxOrdered)\n",
    "toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=10)\n",
    "toolbox.register(\"evaluate\", eval_tsp)\n",
    "\n",
    "# The genetic algorithm \n",
    "# MuPlusLambda \n",
    "# This algorithm is more elitist  and requiere more computations.\n",
    "# the main idea is that here paretns ( mu) and child(lambda) compite between them\n",
    "# The paremeters are initial population, toolbox, mu, lambda, cxpb ( probability of crossover)\n",
    "# mutpb (probability of mutation), ngen (number of generations), stats ( registry of functions), halloffame\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(101)\n",
    "    CXPB, MUTPB, NGEN = 0.7, 0.3, 7\n",
    "    pop = toolbox.population()\n",
    "    MU, LAMBDA = len(pop), len(pop)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    logbook = tools.Logbook()\n",
    "    pop, logbook = algorithms.eaMuPlusLambda(pop,toolbox, MU, LAMBDA, CXPB, MUTPB, NGEN,\n",
    "                                            stats = stats, halloffame=hof)\n",
    "    return pop, logbook\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best, log  = main()\n",
    "    print(\"\\n\",'--'*50)\n",
    "    print(f\"The fitness {best[0].fitness.values} and he better path is : \\n\",)\n",
    "    print(capitals[best[0]])\n",
    "    print(\"--\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6b544",
   "metadata": {},
   "source": [
    "# The real optimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff723265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "paths = list(itertools.permutations(capitals))\n",
    "index, index_aux = 0,0\n",
    "def eval_tsp_brute(paths):\n",
    "    array = []\n",
    "    for path in paths:\n",
    "        route = distanceF(cities_dict[path[0]],cities_dict[path[-1]])\n",
    "        for i in range(len(path)-1):\n",
    "            route = route  +  distanceF(cities_dict[path[i]],cities_dict[path[i+1]])\n",
    "        array.append([route, path])\n",
    "    array.sort(reverse=False, key=lambda x:x[0])\n",
    "    return array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75591bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 951 ms, total: 1min 17s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[34.96071294980095,\n",
       " ('Popayán',\n",
       "  'Armenia',\n",
       "  'Quibdó',\n",
       "  'Montería',\n",
       "  'Barranquilla',\n",
       "  'Ríohacha',\n",
       "  'Yopal',\n",
       "  'Puerto Carreño',\n",
       "  'Mitú',\n",
       "  'Florencia')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "eval_tsp_brute(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
